{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process Wu et al slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import squidpy as sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "slide_names = ['1142243F', '1160920F', 'CID4290', 'CID4465', 'CID44971', 'CID4535']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join('..', '..', 'data', 'wu_et_al')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Junk Breast Cancer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for slide_name in slide_names:\n",
    "    \n",
    "    adata = sc.read_h5ad(os.path.join(data_dir, slide_name, f\"{slide_name}.h5ad\"))\n",
    "    del adata.layers['logcounts']\n",
    "    from squidpy._constants._pkg_constants import Key\n",
    "    import json\n",
    "    from pathlib import Path\n",
    "    from squidpy.read._utils import _load_image, _read_counts\n",
    "    from squidpy.datasets._utils import PathLike\n",
    "    \n",
    "    library_id = slide_name\n",
    "    path = Path(os.path.join(data_dir, slide_name))\n",
    "    adata.uns[Key.uns.spatial] = {}\n",
    "    adata.uns[Key.uns.spatial][library_id] = {}\n",
    "    \n",
    "    adata.uns[Key.uns.spatial][library_id][Key.uns.image_key] = {\n",
    "    res: _load_image(path / f\"{Key.uns.spatial}/tissue_{res}_image.png\") for res in [\"hires\", \"lowres\"]\n",
    "    }\n",
    "    adata.uns[Key.uns.spatial][library_id][\"scalefactors\"] = json.loads(\n",
    "        (path / f\"{Key.uns.spatial}/scalefactors_json.json\").read_bytes()\n",
    "    )\n",
    "    \n",
    "    tissue_positions_file = (\n",
    "    path / \"spatial/tissue_positions.csv\"\n",
    "    if (path / \"spatial/tissue_positions.csv\").exists()\n",
    "    else path / \"spatial/tissue_positions_list.csv\"\n",
    "    )\n",
    "\n",
    "    coords = pd.read_csv(\n",
    "        tissue_positions_file,\n",
    "        header=1 if tissue_positions_file.name == \"tissue_positions.csv\" else None,\n",
    "        index_col=0,\n",
    "    )\n",
    "    coords.columns = [\"in_tissue\", \"array_row\", \"array_col\", \"pxl_col_in_fullres\", \"pxl_row_in_fullres\"]\n",
    "    # https://github.com/scverse/squidpy/issues/657\n",
    "    coords.set_index(coords.index.astype(adata.obs.index.dtype), inplace=True)\n",
    "\n",
    "    adata.obs = pd.merge(adata.obs, coords, how=\"left\", left_index=True, right_index=True)\n",
    "    adata.obsm[Key.obsm.spatial] = adata.obs[[\"pxl_row_in_fullres\", \"pxl_col_in_fullres\"]].values\n",
    "    adata.obs.drop(columns=[\"pxl_row_in_fullres\", \"pxl_col_in_fullres\"], inplace=True)\n",
    "    \n",
    "    obs = pd.read_csv(os.path.join(data_dir, slide_name, \"metadata.csv\"), index_col=0)\n",
    "    adata.obs = adata.obs.merge(obs, left_index=True, right_index=True)\n",
    "\n",
    "    adata.write_h5ad(os.path.join(data_dir, f\"{slide_name}.h5ad\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spiana",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b688e7f183144fde965166e58483e32fc6dbc6fc380ccc51d49ef608da0385a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
