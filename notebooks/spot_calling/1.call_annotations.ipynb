{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import liana as li\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import run_rf_auc, run_stlearn, convert_scanpy, run_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join('..', '..', 'data', 'wu_et_al')\n",
    "dataset_names = ['1160920F', 'CID44971', 'CID4535', '1142243F'] # 'CID4465', 'CID4290 are both basically cancer only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_names = li.mt.bivar.show_functions()['name'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function_names = function_names[0:1]\n",
    "# insert stLearn\n",
    "# dataset_names = [dataset_names[0]]\n",
    "function_names = np.insert(function_names, 0, 'stLearn')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run on all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 1160920F\n",
      "Running stLearn\n",
      "Calculating neighbours...\n",
      "0 spots with no neighbours, 6 median spot neighbours.\n",
      "Spot neighbour indices stored in adata.obsm['spot_neighbours'] & adata.obsm['spot_neigh_bcs'].\n",
      "Altogether 2510 valid L-R pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating backgrounds & testing each LR pair...:   1%|           [ time left: 47:07 ]  "
     ]
    }
   ],
   "source": [
    "performances = {}\n",
    "# Initialize an empty DataFrame\n",
    "efficiency = pd.DataFrame(columns=['dataset_name', 'function_name', 'time'])\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    print(f\"Running {dataset_name}\")\n",
    "    adata = sc.read_h5ad(os.path.join(data_dir, f\"{dataset_name}.h5ad\"))\n",
    "    \n",
    "    adata.uns['function_names'] = function_names\n",
    "    \n",
    "    # to binary\n",
    "    adata.obs['Classification'][adata.obs['Classification'].isna()] = 'Artefact'\n",
    "    adata.obs['spot_label'] = adata.obs['Classification'].str.contains('cancer').astype(int)\n",
    "    \n",
    "    # Preprocess\n",
    "    sc.pp.filter_cells(adata, min_genes=400)\n",
    "    sc.pp.filter_genes(adata, min_cells=20)\n",
    "\n",
    "    adata.layers[\"counts\"] = adata.X.copy()\n",
    "    \n",
    "    sc.pp.normalize_total(adata, inplace=True)\n",
    "    sc.pp.log1p(adata)\n",
    "    \n",
    "    # NOTE: stLearn specific\n",
    "    adata = convert_scanpy(adata)\n",
    "    \n",
    "    # Run all functions\n",
    "    for function_name in function_names:\n",
    "        print(f\"Running {function_name}\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        if function_name == 'stLearn':\n",
    "            run_stlearn(adata)\n",
    "        else:\n",
    "            if function_name not in ['product', 'norm_product']:\n",
    "                standardize = False\n",
    "            else:\n",
    "                standardize = True\n",
    "            \n",
    "            run_local(adata, \n",
    "                      function_name,\n",
    "                      n_perms=100,\n",
    "                      mask_negatives=True,\n",
    "                      standardize=standardize)\n",
    "            \n",
    "        end_time = time.time()\n",
    "        efficiency = efficiency.append({'dataset_name': dataset_name,\n",
    "                                        'function_name': function_name,\n",
    "                                        'time': end_time - start_time},\n",
    "                                       ignore_index=True)\n",
    "        \n",
    "    # eval LR basis\n",
    "    run_rf_auc(adata, dataset_name)\n",
    "    os.makedirs(os.path.join(data_dir, 'results'), exist_ok=True)\n",
    "    performance = adata.uns['performance']\n",
    "    performances[dataset_name] = performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficiency.to_csv(os.path.join('efficiency.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "performance = pd.concat(performances, names=['dataset_name', None])\n",
    "performance.to_csv(\"annotation_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spiana",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b688e7f183144fde965166e58483e32fc6dbc6fc380ccc51d49ef608da0385a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
